{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1351797,
          "sourceType": "datasetVersion",
          "datasetId": 786787
        },
        {
          "sourceId": 10808195,
          "sourceType": "datasetVersion",
          "datasetId": 6709109
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilyuski/deep-emotion-recognition/blob/main/emociones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El proyecto consiste en la detección de las emociones. Para ello, me he basado en el dataset ya desarrollado de kaggle https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data . Dado que ya se había terminado el challenge, he encontrado el dataset de base para poder entrenar mi IA https://www.kaggle.com/datasets/msambare/fer2013"
      ],
      "metadata": {
        "id": "rQJUVfVJchXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activamos GPU P100 !"
      ],
      "metadata": {
        "id": "zhyMqYTXchXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descargamos los paquetes que vayamos a necesitar"
      ],
      "metadata": {
        "id": "LZP3cKQ7chXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:01:02.991470Z",
          "iopub.execute_input": "2025-02-20T21:01:02.991847Z",
          "iopub.status.idle": "2025-02-20T21:01:02.995888Z",
          "shell.execute_reply.started": "2025-02-20T21:01:02.991816Z",
          "shell.execute_reply": "2025-02-20T21:01:02.994872Z"
        },
        "id": "Ku9M5b2RchXn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:01:16.943295Z",
          "iopub.execute_input": "2025-02-20T21:01:16.943649Z",
          "iopub.status.idle": "2025-02-20T21:01:16.947461Z",
          "shell.execute_reply.started": "2025-02-20T21:01:16.943620Z",
          "shell.execute_reply": "2025-02-20T21:01:16.946577Z"
        },
        "id": "TLBo1JjschXo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como ya vimos previamente el dataset del que partimos son imágenes ordenadas en carpetas de la siguiente manera para cada caso, test y train. Por ello para poder trabajar con ellas, las vamos a cargar con ImageDataGenerator de Keras.\n",
        "!"
      ],
      "metadata": {
        "id": "1AF4osVWchXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T20:58:50.893395Z",
          "iopub.execute_input": "2025-02-20T20:58:50.893811Z",
          "iopub.status.idle": "2025-02-20T20:58:50.897981Z",
          "shell.execute_reply.started": "2025-02-20T20:58:50.893783Z",
          "shell.execute_reply": "2025-02-20T20:58:50.896977Z"
        },
        "id": "Cnr-9xz0chXo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indicamos las rutas de las imágenes, tamaño de la imágen, lote y emociones. También laas vamos a normalizar"
      ],
      "metadata": {
        "id": "gVx3LrDVchXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/kaggle/input/fer2013/train'\n",
        "test_dir = '/kaggle/input/fer2013/test'\n",
        "\n",
        "img_size = (48, 48)  # Tamaño de las imágenes\n",
        "batch_size = 64      # Tamaño del lote\n",
        "num_classes = 7      # Número de clases (emociones)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0)  # Normalizar imágenes\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T20:58:53.225970Z",
          "iopub.execute_input": "2025-02-20T20:58:53.226267Z",
          "iopub.status.idle": "2025-02-20T20:58:53.230594Z",
          "shell.execute_reply.started": "2025-02-20T20:58:53.226245Z",
          "shell.execute_reply": "2025-02-20T20:58:53.229685Z"
        },
        "id": "FYa_txAYchXp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "También vamos a dividir en la parte de entrenamiento y test"
      ],
      "metadata": {
        "id": "p4CXPVxxchXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T20:58:55.216839Z",
          "iopub.execute_input": "2025-02-20T20:58:55.217138Z",
          "iopub.status.idle": "2025-02-20T20:59:11.027348Z",
          "shell.execute_reply.started": "2025-02-20T20:58:55.217116Z",
          "shell.execute_reply": "2025-02-20T20:59:11.026587Z"
        },
        "id": "B7HoorR9chXp",
        "outputId": "dfeef96f-2a60-43e3-fed0-f78f117b6b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 28709 images belonging to 7 classes.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T20:59:14.315988Z",
          "iopub.execute_input": "2025-02-20T20:59:14.316302Z",
          "iopub.status.idle": "2025-02-20T20:59:19.144458Z",
          "shell.execute_reply.started": "2025-02-20T20:59:14.316277Z",
          "shell.execute_reply": "2025-02-20T20:59:19.143750Z"
        },
        "id": "wFspSKUuchXq",
        "outputId": "0b2f8f5a-dfff-401d-a129-034d71257aac"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 7178 images belonging to 7 classes.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que tebemos las imágenes preparadasm vamos a construir y compilar el modelo"
      ],
      "metadata": {
        "id": "Gpm8tnX9chXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descargamos alguna librería más"
      ],
      "metadata": {
        "id": "6GYRvL7uchXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T20:59:24.988574Z",
          "iopub.execute_input": "2025-02-20T20:59:24.988948Z",
          "iopub.status.idle": "2025-02-20T20:59:24.993102Z",
          "shell.execute_reply.started": "2025-02-20T20:59:24.988921Z",
          "shell.execute_reply": "2025-02-20T20:59:24.992029Z"
        },
        "id": "TCn7s2dPchXq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:01:55.143042Z",
          "iopub.execute_input": "2025-02-20T21:01:55.143374Z",
          "iopub.status.idle": "2025-02-20T21:01:55.147399Z",
          "shell.execute_reply.started": "2025-02-20T21:01:55.143344Z",
          "shell.execute_reply": "2025-02-20T21:01:55.146385Z"
        },
        "id": "st756wN3chXq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    Input(shape=(48, 48, 1)),  # Capa Input explícita\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')  # 7 emociones\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:01:58.630398Z",
          "iopub.execute_input": "2025-02-20T21:01:58.630784Z",
          "iopub.status.idle": "2025-02-20T21:01:58.674653Z",
          "shell.execute_reply.started": "2025-02-20T21:01:58.630752Z",
          "shell.execute_reply": "2025-02-20T21:01:58.673926Z"
        },
        "id": "sJ_jDF8YchXq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que he tenido advertencia he tenido que modificar el código !"
      ],
      "metadata": {
        "id": "iN9VGn78chXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compilamos el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:02:11.910636Z",
          "iopub.execute_input": "2025-02-20T21:02:11.910977Z",
          "iopub.status.idle": "2025-02-20T21:02:11.923991Z",
          "shell.execute_reply.started": "2025-02-20T21:02:11.910950Z",
          "shell.execute_reply": "2025-02-20T21:02:11.923218Z"
        },
        "id": "xbXLjtCdchXq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumen del modelo\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:02:13.988945Z",
          "iopub.execute_input": "2025-02-20T21:02:13.989247Z",
          "iopub.status.idle": "2025-02-20T21:02:14.010321Z",
          "shell.execute_reply.started": "2025-02-20T21:02:13.989224Z",
          "shell.execute_reply": "2025-02-20T21:02:14.009333Z"
        },
        "id": "LelDm4xVchXq",
        "outputId": "eea3a3b2-6ac7-4ee2-f02b-be66927304fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"sequential_1\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m819,328\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m903\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,328</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m839,047\u001b[0m (3.20 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">839,047</span> (3.20 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m839,047\u001b[0m (3.20 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">839,047</span> (3.20 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es ahora cuando vamos a entrenar el modelo con los generadores de datos y los ** epoch ***"
      ],
      "metadata": {
        "id": "wdwBVMItchXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "# Entremos el modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // batch_size\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:02:17.644965Z",
          "iopub.execute_input": "2025-02-20T21:02:17.645288Z",
          "iopub.status.idle": "2025-02-20T21:05:34.578996Z",
          "shell.execute_reply.started": "2025-02-20T21:02:17.645261Z",
          "shell.execute_reply": "2025-02-20T21:05:34.578212Z"
        },
        "id": "hGNThE0hchXr",
        "outputId": "727a3653-4bf4-472f-cc15-b8963ee9b21e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 260ms/step - accuracy: 0.2746 - loss: 1.7799 - val_accuracy: 0.4127 - val_loss: 1.5359\nEpoch 2/5\n\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3906 - loss: 1.5882",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3906 - loss: 1.5882 - val_accuracy: 0.4000 - val_loss: 1.5876\nEpoch 3/5\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 73ms/step - accuracy: 0.4062 - loss: 1.5499 - val_accuracy: 0.4588 - val_loss: 1.4191\nEpoch 4/5\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.5000 - loss: 1.4463 - val_accuracy: 0.5000 - val_loss: 1.4144\nEpoch 5/5\n\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 67ms/step - accuracy: 0.4403 - loss: 1.4533 - val_accuracy: 0.4802 - val_loss: 1.3635\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lTXXg0KKchXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Me he encontrado el siguiente error, por lo que he tenido que chequerar el uso de GPU así como instalar la version de tensorflow==2.15 así como modificar algunas líneas de código !"
      ],
      "metadata": {
        "id": "iRMttEz1chXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T20:52:27.873108Z",
          "iopub.execute_input": "2025-02-20T20:52:27.873426Z",
          "iopub.status.idle": "2025-02-20T20:52:28.066808Z",
          "shell.execute_reply.started": "2025-02-20T20:52:27.873403Z",
          "shell.execute_reply": "2025-02-20T20:52:28.065951Z"
        },
        "id": "f9pg8eufchXr",
        "outputId": "8eb053ec-55a2-4a81-9158-caea684951ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Thu Feb 20 20:52:27 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0             33W /  250W |     535MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T20:53:46.600253Z",
          "iopub.execute_input": "2025-02-20T20:53:46.600595Z",
          "iopub.status.idle": "2025-02-20T20:54:43.169220Z",
          "shell.execute_reply.started": "2025-02-20T20:53:46.600566Z",
          "shell.execute_reply": "2025-02-20T20:54:43.167655Z"
        },
        "id": "bKECBIzMchXr",
        "outputId": "4b4d5b6f-67dc-47d2-d8de-3449dc8eff30"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting tensorflow==2.15\n  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (18.1.1)\nCollecting ml-dtypes~=0.2.0 (from tensorflow==2.15)\n  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (4.12.2)\nCollecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15)\n  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.37.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.68.1)\nCollecting tensorboard<2.16,>=2.15 (from tensorflow==2.15)\n  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\nCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15)\n  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras<2.16,>=2.15.0 (from tensorflow==2.15)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15) (0.45.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15) (2.4.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.27.0)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (1.2.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.7)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.1.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow==2.15) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.2.2)\nDownloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, keras, tensorboard, ml-dtypes, tensorflow\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.17.0\n    Uninstalling wrapt-1.17.0:\n      Successfully uninstalled wrapt-1.17.0\n  Attempting uninstall: keras\n    Found existing installation: keras 3.5.0\n    Uninstalling keras-3.5.0:\n      Successfully uninstalled keras-3.5.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.17.1\n    Uninstalling tensorboard-2.17.1:\n      Successfully uninstalled tensorboard-2.17.1\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.17.1\n    Uninstalling tensorflow-2.17.1:\n      Successfully uninstalled tensorflow-2.17.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.15.0 which is incompatible.\ntensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.15.0 which is incompatible.\ntensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\ntf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 wrapt-1.14.1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardamos el modelo"
      ],
      "metadata": {
        "id": "euU5387MchXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/kaggle/working/emotion_model.h5')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:06:41.623487Z",
          "iopub.execute_input": "2025-02-20T21:06:41.623842Z",
          "iopub.status.idle": "2025-02-20T21:06:41.691220Z",
          "shell.execute_reply.started": "2025-02-20T21:06:41.623818Z",
          "shell.execute_reply": "2025-02-20T21:06:41.690580Z"
        },
        "id": "MhtSzlCZchXr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a probar si el modelo funciona correctamente cargándole una foto de prueba"
      ],
      "metadata": {
        "id": "rUksOuMHchXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalamos alguna librería más"
      ],
      "metadata": {
        "id": "pYKfiSGschXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:07:27.302470Z",
          "iopub.execute_input": "2025-02-20T21:07:27.302793Z",
          "iopub.status.idle": "2025-02-20T21:07:27.597576Z",
          "shell.execute_reply.started": "2025-02-20T21:07:27.302767Z",
          "shell.execute_reply": "2025-02-20T21:07:27.596895Z"
        },
        "id": "VD5bOV01chXr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos una de las fotos que he subido"
      ],
      "metadata": {
        "id": "cvVrN3WWchXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/kaggle/input/foto-prueba/_104901498_angry4.jpg'\n",
        "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "image = cv2.resize(image, (48, 48))  # Redimensionar a 48x48\n",
        "image = image.reshape(1, 48, 48, 1) / 255.0  # Normalizar y reformatear\n",
        "\n",
        "#La mostramos\n",
        "plt.imshow(image[0, :, :, 0], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:18:32.342637Z",
          "iopub.execute_input": "2025-02-20T21:18:32.342935Z",
          "iopub.status.idle": "2025-02-20T21:18:32.399321Z",
          "shell.execute_reply.started": "2025-02-20T21:18:32.342912Z",
          "shell.execute_reply": "2025-02-20T21:18:32.398422Z"
        },
        "id": "TqJCI7OgchXr",
        "outputId": "31065ca9-0f91-44cd-944d-0f0e69698cf0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos la predicción"
      ],
      "metadata": {
        "id": "WyMG_h9dchXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "loQ1UfGmchXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = ['Enojo', 'Asco', 'Miedo', 'Felicidad', 'Tristeza', 'Sorpresa', 'Neutral']\n",
        "prediction = model.predict(image)\n",
        "predicted_emotion = emotions[np.argmax(prediction)]\n",
        "\n",
        "print(f\"Emoción predicha: {predicted_emotion}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T21:18:37.298998Z",
          "iopub.execute_input": "2025-02-20T21:18:37.299307Z",
          "iopub.status.idle": "2025-02-20T21:18:37.361705Z",
          "shell.execute_reply.started": "2025-02-20T21:18:37.299283Z",
          "shell.execute_reply": "2025-02-20T21:18:37.360907Z"
        },
        "id": "epkbAKrmchXr",
        "outputId": "dcdcbc10-6e67-4e46-da3b-85daae5721c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\nEmoción predicha: Sorpresa\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RT2XFGSfchXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por lo que he podido ver a nivel de dataset las imágenes de enfado con las que se ha entrenado son mucho más exageradas que la foto de enfado usada, por lo que efectivamente la foto se asimila mas a las de dataset de \"Enojo\""
      ],
      "metadata": {
        "id": "49i--SWochXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso la imágen"
      ],
      "metadata": {
        "id": "LfrRJDW7chXv"
      }
    }
  ]
}
